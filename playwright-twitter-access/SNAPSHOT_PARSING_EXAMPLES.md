# Snapshot æ•°æ®è§£æç¤ºä¾‹

æœ¬æ–‡æ¡£å±•ç¤ºå¦‚ä½•è§£æ Playwright browser å·¥å…·è¿”å›çš„ snapshot æ•°æ®ã€‚

---

## å®ä¾‹ 1: è§£æç”¨æˆ·ä¿¡æ¯

### Snapshot ç»“æ„
```json
{
  "document": {
    "banner": {
      "main": {
        "heading": "Elon Musk Verified account @elonmusk 98.1K posts",
        "text": "1,290 Following",
        "link": "235.5M Followers",
        "link": "Joined June 2009"
      }
    }
  }
}
```

### Python è§£æä»£ç 
```python
import json

def parse_user_info_snapshot(snapshot_data):
    """è§£æç”¨æˆ·ä¿¡æ¯ snapshop"""
    if not snapshot_data or 'document' not in snapshot_data:
        return None

    document = snapshot_data['document']
    banner = document.get('banner', {})
    main = banner.get('main', {})

    # æå–ç”¨æˆ·å
    user_data = {
        'username': None,
        'verified': False,
        'posts': 0,
        'following': 0,
        'followers': 0,
        'joined': None
    }

    # éå† main çš„å­å…ƒç´ 
    for element in main:
        if 'heading' in element:
            # ç”¨æˆ·å + å¸–å­æ•°
            heading_text = element['heading']
            parts = heading_text.split()
            if len(parts) >= 2:
                user_data['username'] = parts[0]
                user_data['verified'] = 'Verified' in heading_text

                # æå–å¸–å­æ•°
                for part in parts:
                    if 'posts' in part.lower():
                        num_str = part.split()[0]
                        if 'K' in num_str:
                            user_data['posts'] = float(num_str.replace('K', '')) * 1000
                        elif 'M' in num_str:
                            user_data['posts'] = float(num_str.replace('M', '')) * 1000000
                        else:
                            user_data['posts'] = int(num_str)

        elif 'text' in element:
            text = element['text']
            if 'Following' in text:
                # æå–å…³æ³¨æ•°
                num_str = text.split()[0]
                if 'K' in num_str:
                    user_data['following'] = float(num_str.replace('K', '')) * 1000
                elif 'M' in num_str:
                    user_data['following'] = float(num_str.replace('M', '')) * 1000000
                else:
                    user_data['following'] = int(num_str)
            elif 'Followers' in text and isinstance(element, dict) and 'link' in element:
                # æå–ç²‰ä¸æ•°
                link_text = element['link']
                num_str = link_text.split()[0]
                if 'K' in num_str:
                    user_data['followers'] = float(num_str.replace('K', '')) * 1000
                elif 'M' in num_str:
                    user_data['followers'] = float(num_str.replace('M', '')) * 1000000
                else:
                    user_data['followers'] = int(num_str)

        elif 'link' in element and 'Joined' in element.get('link', ''):
            # åŠ å…¥æ—¶é—´
            user_data['joined'] = element['link']

    return user_data

# ä½¿ç”¨ç¤ºä¾‹
with open('outputs/elonmusk_snapshot.json', 'r') as f:
    snapshot = json.load(f)

user_info = parse_user_info_snapshot(snapshot)
print(json.dumps(user_info, indent=2))
```

---

## å®ä¾‹ 2: è§£ææ¨æ–‡æ•°æ®

### Snapshot ç»“æ„
```json
{
  "document": {
    "banner": {
      "main": {
        "region": "Conversation",
        "article": [
          {
            "link": "Elon Musk Verified account",
            "link": "@elonmusk",
            "link": "7 hours ago",
            "text": "æ¨æ–‡å†…å®¹...",
            "group": {
              "button": "3560 Replies",
              "button": "8964 reposts",
              "button": "71087 Likes",
              "link": "35753772 views"
            }
          }
        ]
      }
    }
  }
}
```

### Python è§£æä»£ç 
```python
def parse_tweet_snapshot(snapshot_data):
    """è§£ææ¨æ–‡ snapshot"""
    if not snapshot_data or 'document' not in snapshot_data:
        return None

    document = snapshot_data['document']
    banner = document.get('banner', {})
    main = banner.get('main', {})

    # æŸ¥æ‰¾ Conversation region
    conversation_region = None
    for element in main:
        if isinstance(element, dict) and 'region' in element:
            if element.get('region') == 'Conversation':
                conversation_region = element
                break

    if not conversation_region:
        return None

    # æå–ç¬¬ä¸€æ¡ articleï¼ˆä¸»æ¨æ–‡ï¼‰
    articles = conversation_region.get('article', [])
    if not articles:
        return None

    tweet_article = articles[0]

    # è§£ææ¨æ–‡æ•°æ®
    tweet_data = {
        'author': None,
        'username': None,
        'verified': False,
        'time': None,
        'content': None,
        'stats': {
            'replies': 0,
            'reposts': 0,
            'likes': 0,
            'views': 0
        }
    }

    for element in tweet_article:
        if 'link' in element:
            link_text = element['link']

            # ç”¨æˆ·ä¿¡æ¯
            if 'Verified account' in link_text:
                tweet_data['author'] = link_text.split(' Verified')[0]
                tweet_data['verified'] = True
            elif link_text.startswith('@'):
                tweet_data['username'] = link_text
            elif 'hours ago' in link_text.lower() or 'minutes ago' in link_text.lower():
                tweet_data['time'] = link_text

        elif 'text' in element:
            tweet_data['content'] = element['text']

        elif 'group' in element:
            # ç»Ÿè®¡æ•°æ®
            group = element['group']
            for stat_element in group:
                if 'button' in stat_element:
                    stat_text = stat_element['button']
                    if 'Replies' in stat_text:
                        num_str = stat_text.split()[0]
                        tweet_data['stats']['replies'] = parse_number(num_str)
                    elif 'reposts' in stat_text.lower():
                        num_str = stat_text.split()[0]
                        tweet_data['stats']['reposts'] = parse_number(num_str)
                    elif 'Likes' in stat_text:
                        num_str = stat_text.split()[0]
                        tweet_data['stats']['likes'] = parse_number(num_str)
                elif 'link' in stat_element and 'views' in stat_element['link']:
                    num_str = stat_element['link'].split()[0]
                    tweet_data['stats']['views'] = parse_number(num_str)

    return tweet_data

def parse_number(num_str):
    """è§£ææ•°å­—å­—ç¬¦ä¸²ï¼ˆæ”¯æŒ K/M åç¼€ï¼‰"""
    num_str = num_str.replace(',', '').replace('.', '')  # ç§»é™¤åˆ†éš”ç¬¦

    if 'K' in num_str:
        return int(float(num_str.replace('K', '')) * 1000)
    elif 'M' in num_str:
        return int(float(num_str.replace('M', '')) * 1000000)
    elif 'B' in num_str:
        return int(float(num_str.replace('B', '')) * 1000000000)
    else:
        return int(num_str) if num_str.isdigit() else 0

# ä½¿ç”¨ç¤ºä¾‹
with open('outputs/2027644868881957020_tweet_snapshot.json', 'r') as f:
    snapshot = json.load(f)

tweet_data = parse_tweet_snapshot(snapshot)
print(json.dumps(tweet_data, indent=2))
```

---

## å®ä¾‹ 3: è§£æå›å¤åˆ—è¡¨

### Python è§£æä»£ç 
```python
def parse_replies_snapshot(snapshot_data):
    """è§£æå›å¤åˆ—è¡¨ snapshot"""
    if not snapshot_data or 'document' not in snapshot_data:
        return []

    document = snapshot_data['document']
    banner = document.get('banner', {})
    main = banner.get('main', {})

    # æŸ¥æ‰¾ Conversation region
    conversation_region = None
    for element in main:
        if isinstance(element, dict) and 'region' in element:
            if element.get('region') == 'Conversation':
                conversation_region = element
                break

    if not conversation_region:
        return []

    # æå–æ‰€æœ‰ articleï¼ˆä¸»æ¨æ–‡ + å›å¤ï¼‰
    articles = conversation_region.get('article', [])
    if not articles or len(articles) < 2:
        return []

    # è·³è¿‡ç¬¬ä¸€æ¡ï¼ˆä¸»æ¨æ–‡ï¼‰ï¼Œæå–å›å¤
    replies = []
    for article in articles[1:]:  # ä»ç¬¬äºŒæ¡å¼€å§‹æ˜¯å›å¤
        reply_data = {
            'author': None,
            'username': None,
            'verified': False,
            'time': None,
            'content': None,
            'images': []
        }

        for element in article:
            if 'link' in element:
                link_text = element['link']

                if 'Verified account' in link_text:
                    reply_data['author'] = link_text.split(' Verified')[0]
                    reply_data['verified'] = True
                elif link_text.startswith('@'):
                    reply_data['username'] = link_text
                elif 'hours ago' in link_text.lower() or 'minutes ago' in link_text.lower():
                    reply_data['time'] = link_text
                elif link_text == 'Image':
                    # å›¾ç‰‡é“¾æ¥
                    if '/url' in element:
                        reply_data['images'].append(element['/url'])

            elif 'text' in element:
                reply_data['content'] = element['text']

        replies.append(reply_data)

    return replies

# ä½¿ç”¨ç¤ºä¾‹
with open('outputs/2027644868881957020_tweet_snapshot.json', 'r') as f:
    snapshot = json.load(f)

replies = parse_replies_snapshot(snapshot)
print(f"æ‰¾åˆ° {len(replies)} æ¡å›å¤:")
for i, reply in enumerate(replies, 1):
    print(f"\nå›å¤ {i}:")
    print(f"  ä½œè€…: {reply['author']} (@{reply['username']})")
    print(f"  æ—¶é—´: {reply['time']}")
    print(f"  å†…å®¹: {reply['content'][:50]}...")
```

---

## å®ä¾‹ 4: å®Œæ•´ç»¼åˆè§£æ

```python
def parse_twitter_snapshot(snapshot_data):
    """ç»¼åˆè§£æ Twitter snapshot"""
    if not snapshot_data or 'document' not in snapshot_data:
        return None

    document = snapshot_data['document']
    banner = document.get('banner', {})
    main = banner.get('main', {})

    result = {
        'user': None,
        'tweets': [],
        'replies': []
    }

    # æ£€æµ‹é¡µé¢ç±»å‹
    page_type = None
    for element in main:
        if 'heading' in element and 'Verified account' in element['heading']:
            # å¯èƒ½æ˜¯ç”¨æˆ·ä¸»é¡µæˆ–æ¨æ–‡è¯¦æƒ…
            if any('region' in e and 'Conversation' in e['region'] for e in main if isinstance(e, dict)):
                page_type = 'tweet'
            else:
                page_type = 'user'
            break

    if page_type == 'user':
        # è§£æç”¨æˆ·ä¸»é¡µ
        result['user'] = parse_user_info_snapshot(snapshot_data)
        # TODO: è§£ææ¨æ–‡åˆ—è¡¨
    elif page_type == 'tweet':
        # è§£ææ¨æ–‡è¯¦æƒ…
        result['tweets'] = [parse_tweet_snapshot(snapshot_data)]
        result['replies'] = parse_replies_snapshot(snapshot_data)

    return result

# ä½¿ç”¨ç¤ºä¾‹
with open('outputs/2027644868881957020_tweet_snapshot.json', 'r') as f:
    snapshot = json.load(f)

parsed_data = parse_twitter_snapshot(snapshot)
print(json.dumps(parsed_data, indent=2))
```

---

## ğŸ“ è§£æå™¨ä½¿ç”¨æµç¨‹

### 1. è·å– Snapshot
```bash
browser action=snapshot depth=5 refs=role > snapshot.json
```

### 2. åŠ è½½ JSON
```python
import json
with open('snapshot.json', 'r') as f:
    snapshot = json.load(f)
```

### 3. è°ƒç”¨è§£æå™¨
```python
# ç”¨æˆ·ä¿¡æ¯
user_info = parse_user_info_snapshot(snapshot)

# æ¨æ–‡æ•°æ®
tweet_data = parse_tweet_snapshot(snapshot)

# å›å¤åˆ—è¡¨
replies = parse_replies_snapshot(snapshot)

# ç»¼åˆè§£æ
parsed = parse_twitter_snapshot(snapshot)
```

### 4. å¤„ç†ç»“æœ
```python
print(json.dumps(parsed, indent=2))
# æˆ–
import pandas as pd
df = pd.json_normalize(parsed)
```

---

## ğŸ“Š è¾“å‡ºæ ¼å¼ç¤ºä¾‹

### ç”¨æˆ·ä¿¡æ¯
```json
{
  "username": "elonmusk",
  "verified": true,
  "posts": 98100,
  "following": 1290,
  "followers": 235500000,
  "joined": "Joined June 2009"
}
```

### æ¨æ–‡æ•°æ®
```json
{
  "author": "Elon Musk",
  "username": "elonmusk",
  "verified": true,
  "time": "7 hours ago",
  "content": "æ¨æ–‡å†…å®¹...",
  "stats": {
    "replies": 3560,
    "reposts": 8964,
    "likes": 71087,
    "views": 35753772
  }
}
```

### å›å¤åˆ—è¡¨
```json
[
  {
    "author": "Anas",
    "username": "Anas_founder",
    "verified": true,
    "time": "6 hours ago",
    "content": "Elon musk's keyboard",
    "images": []
  },
  {
    "author": "Soda Pop Comix",
    "username": "SodaPopComix",
    "verified": true,
    "time": "12 minutes ago",
    "content": "",
    "images": ["https://x.com/..."]
  }
]
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
```python
def safe_parse(snapshot_data):
    try:
        return parse_tweet_snapshot(snapshot_data)
    except Exception as e:
        print(f"è§£æå¤±è´¥: {e}")
        return None
```

### 2. æ•°æ®éªŒè¯
```python
def validate_tweet_data(tweet_data):
    if not tweet_data:
        return False
    required_fields = ['author', 'username', 'content']
    return all(field in tweet_data for field in required_fields)
```

### 3. æ‰¹é‡å¤„ç†
```python
import os
import glob

def batch_parse_snapshots(directory):
    results = []
    for json_file in glob.glob(f"{directory}/*.json"):
        with open(json_file, 'r') as f:
            snapshot = json.load(f)
        parsed = parse_tweet_snapshot(snapshot)
        if parsed:
            results.append(parsed)
    return results
```

---

*æ›´æ–°æ—¶é—´: 2026-02-28*